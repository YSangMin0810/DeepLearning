# -*- coding: utf-8 -*-
"""colab.py37.CIFAR Challenge(201710788 유상민).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cklEC9mZOfL1EFMxpmGqRjjgh8CE4xGL
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.init as init
import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.autograd import Variable
import matplotlib.pyplot as plt

#(8) learning rate decay
from torch.optim import lr_scheduler

batch_size=20
learning_rate=0.002
num_epoch=120

cifar_train=dset.CIFAR10("CIFAR10/",train=True, transform=transforms.ToTensor(), target_transform=None, download=True)
# cifar_train=dset.CIFAR10("CIFAR10/",train=True,
#                          transform=transforms.Compose([
#                             transforms.Scale(36),
#                             transforms.CenterCrop(32),
#                             transforms.RandomHorizontalFlip(),
#                             transforms.Lambda(lambda x: x.rotate(90)),
#                             transforms.ToTensor()
#                          ]))
cifar_test=dset.CIFAR10("CIFAR10/",train=False, transform=transforms.ToTensor(), target_transform=None, download=True)
# cifar_train=dset.CIFAR10("CIFAR10/",train=True,
#                          transform=transforms.Compose([
#                             transforms.ToTensor(),
#                             transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),
#                          ])
#                          , target_transform=None, download=False)
# cifar_test=dset.CIFAR10("CIFAR10/",train=False,
#                          transform=transforms.Compose([
#                             transforms.ToTensor(),
#                             transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),
#                          ])
#                          , target_transform=None, download=False)

print ("cifar_train 길이:", len(cifar_train))
print ("cifar_test 길이:", len(cifar_test))

#데이터 하나 형태
image, label = cifar_train.__getitem__(1) #1번째 데이터
print ("image data 형태:",image.size())
print ("label: ",label)
#그리기
img = image.numpy()

#(3,32,32)->(32,32,3)
r,g,b = img[0,:,:],img[1,:,:],img[2,:,:]
#img = imgreshape(img.shape[1],img.shape[2],img.shape[0])
img2 = np.zeros((img.shape[1],img.shape[2],img.shape[0]))
img2[:,:,0],img2[:,:,1],img2[:,:,2] = r,g,b

plt.title("label: %d" %label )
plt.imshow(img2,interpolation='bicubic')
plt.show()

def ComputeAccr(dloader, imodel):
    correct = 0
    total = 0

    for j, [imgs, labels] in enumerate(dloader): #batch_size 만큼
        img = Variable(imgs,volatile=True).cuda()
        label = Variable(labels).cuda()

        output = imodel.forward(img)
        _, output_index = torch.max(output,1)

        total += label.size(0)
        correct += (output_index == label).sum().float()
    print("Accuracy of Test Data: {}".format(100*correct/total))

#=== 3. 데이터 로드함수 ===
train_loader=torch.utils.data.DataLoader(list(cifar_train)[:], batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)
test_loader=torch.utils.data.DataLoader(list(cifar_test), batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)

#=== 4. 모델 선언 ===
class CNN(nn.Module):
    def __init__(self):
        super(CNN,self).__init__()
        self.layer=nn.Sequential(
            nn.Conv2d(3,16,3,padding=1),
            nn.ReLU(),
            #nn.Dropout2d(0.2),
            nn.BatchNorm2d(16),
            nn.Conv2d(16,32,3,padding=1),
            nn.ReLU(),
            #nn.Dropout2d(0.2),
            nn.BatchNorm2d(32),
            nn.MaxPool2d(2,2),
            nn.Conv2d(32,64,3,padding=1),
            nn.ReLU(),
            #nn.Dropout2d(0.2),
            nn.BatchNorm2d(64),
            nn.MaxPool2d(2,2)
        )
        self.fc_layer=nn.Sequential(
            nn.Linear(64*8*8,100),
            nn.ReLU(),
            #nn.Dropout2d(0,2),
            nn.BatchNorm1d(100),
            nn.Linear(100,10)
        )
        #weight initalization
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                init.kaiming_normal(m.weight.data)
                m.bias.data.fill_(0)
            if isinstance(m, nn.Linear):
                init.kaiming_normal(m.weight.data)
                m.bias.data.fill_(0)

    def forward(self,x):
        out=self.layer(x)
        out=out.view(batch_size,-1)
        out=self.fc_layer(out)

        return out
model=CNN().cuda()

#=== 5. loss, optimizer ===
loss_func=nn.CrossEntropyLoss()
#optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)
optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate) #Adam
scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.2)
model.train()
#=== 6. 학습 ===
for i in range(num_epoch):
    for j,[image, label]in enumerate(train_loader):
        x=Variable(image).cuda()
        y_=Variable(label).cuda()

        optimizer.zero_grad()
        output=model.forward(x)
        loss=loss_func(output,y_)
        loss.backward()
        optimizer.step()

        if j%1000==0:
            print(j,loss)

"""naive model 테스트"""

ComputeAccr(test_loader, model)

"""Drop out"""

model.eval()
ComputeAccr(test_loader, model)

"""Data augmentation"""

ComputeAccr(test_loader, model)

"""Weight initalization"""

model.eval()
ComputeAccr(test_loader, model)

"""Data Normalizaion"""

model.eval()
ComputeAccr(test_loader, model)

"""Batch normalizaion"""

model.eval()
ComputeAccr(test_loader, model)

"""Adam"""

model.eval()
ComputeAccr(test_loader, model)

"""learning rate decay"""

model.eval()
ComputeAccr(test_loader, model)

#netname='/content/drive/MyDrive/my_net01.pkl'
#torch.save(model,netname, )

#netname='/content/drive/MyDrive/my_net01.pkl'
#model = torch.load(netname)
#model.eval()
#ComputeAccr(test_loader,model)

"""Drop out 유/무 비교"""

model.eval()
ComputeAccr(test_loader, model)

model.eval()
ComputeAccr(test_loader, model)

"""Adam/ SGD 비교"""

model.eval()
ComputeAccr(test_loader, model)

model.eval()
ComputeAccr(test_loader, model)

model.eval()
ComputeAccr(test_loader, model)

"""Learning rate decay 유/무 비교"""

model.eval()
ComputeAccr(test_loader, model)

netname='/content/drive/MyDrive/my_net02.pkl'
torch.save(model,netname, )

netname='/content/drive/MyDrive/my_net02.pkl'
model = torch.load(netname)
model.eval()
ComputeAccr(test_loader,model)

model.eval()
ComputeAccr(test_loader, model)

netname='/content/drive/MyDrive/my_net03.pkl'
torch.save(model,netname, )

"""Data augmentation 유/무 비교"""

model.eval()
ComputeAccr(test_loader, model)

model.eval()
ComputeAccr(test_loader, model)

"""최종모델 epoch수 비교"""

netname='/content/drive/MyDrive/my_net03.pkl'
model = torch.load(netname)
model.eval()
ComputeAccr(test_loader,model)

model.eval()
ComputeAccr(test_loader, model)

model.eval()
ComputeAccr(test_loader, model)

"""최종 정확도"""

model.eval()
ComputeAccr(test_loader, model)

netname='/content/drive/MyDrive/my_net04.pkl'
torch.save(model,netname, )

"""성능확인"""

netname='/content/drive/MyDrive/my_net04.pkl'
model = torch.load(netname)
model.eval()
ComputeAccr(test_loader,model)